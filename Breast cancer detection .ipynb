{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7c31cf-54ca-4cc9-a811-6cc4221bbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 784 images belonging to 2 classes.\n",
      "Found 195 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 39s 2s/step - loss: 0.8845 - accuracy: 0.7274 - val_loss: 0.4496 - val_accuracy: 0.7865\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.3673 - accuracy: 0.7899 - val_loss: 0.3740 - val_accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.3271 - accuracy: 0.8484 - val_loss: 0.3992 - val_accuracy: 0.8177\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2978 - accuracy: 0.8577 - val_loss: 0.4101 - val_accuracy: 0.7969\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.2869 - accuracy: 0.8564 - val_loss: 0.3932 - val_accuracy: 0.7760\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 24s 1s/step - loss: 0.2575 - accuracy: 0.8856 - val_loss: 0.5015 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2728 - accuracy: 0.8697 - val_loss: 0.3801 - val_accuracy: 0.8021\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2603 - accuracy: 0.8870 - val_loss: 0.4336 - val_accuracy: 0.8021\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 31s 1s/step - loss: 0.2412 - accuracy: 0.8949 - val_loss: 0.4108 - val_accuracy: 0.7812\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 27s 1s/step - loss: 0.2593 - accuracy: 0.8777 - val_loss: 0.3994 - val_accuracy: 0.7865\n",
      "7/7 [==============================] - 2s 245ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.81      0.66      0.73       154\n",
      "   Malignant       0.25      0.41      0.31        41\n",
      "\n",
      "    accuracy                           0.61       195\n",
      "   macro avg       0.53      0.54      0.52       195\n",
      "weighted avg       0.69      0.61      0.64       195\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Data preparation\n",
    "data_dir = r'C:\\Users\\Nida\\Downloads\\archive (1)\\8863'  # Update with the actual path\n",
    "\n",
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Model building\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "validation_generator.reset()\n",
    "predictions = model.predict(validation_generator)\n",
    "predictions = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "print(classification_report(validation_generator.classes, predictions, target_names=['Benign', 'Malignant']))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(validation_generator.classes, predictions)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.xticks([0, 1], ['Benign', 'Malignant'])\n",
    "plt.yticks([0, 1], ['Benign', 'Malignant'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13624ff0-cc09-4611-b16e-2577b94e3a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 784 images belonging to 2 classes.\n",
      "Found 195 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 734s 31s/step - loss: 0.5005 - accuracy: 0.7899 - val_loss: 0.7008 - val_accuracy: 0.6302\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 590s 25s/step - loss: 0.3653 - accuracy: 0.8298 - val_loss: 0.4110 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 569s 24s/step - loss: 0.3054 - accuracy: 0.8497 - val_loss: 0.4138 - val_accuracy: 0.7708\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 561s 24s/step - loss: 0.3079 - accuracy: 0.8564 - val_loss: 0.3607 - val_accuracy: 0.8177\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 562s 24s/step - loss: 0.2933 - accuracy: 0.8577 - val_loss: 0.4615 - val_accuracy: 0.7865\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 569s 24s/step - loss: 0.2561 - accuracy: 0.8803 - val_loss: 0.5313 - val_accuracy: 0.7448\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 729s 30s/step - loss: 0.2503 - accuracy: 0.8976 - val_loss: 0.4326 - val_accuracy: 0.7708\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 705s 30s/step - loss: 0.2550 - accuracy: 0.8896 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 591s 25s/step - loss: 0.2657 - accuracy: 0.8843 - val_loss: 0.3843 - val_accuracy: 0.8385\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 594s 25s/step - loss: 0.2473 - accuracy: 0.8870 - val_loss: 0.3145 - val_accuracy: 0.8698\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 577s 24s/step - loss: 0.2182 - accuracy: 0.9109 - val_loss: 0.3872 - val_accuracy: 0.8021\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 589s 25s/step - loss: 0.2289 - accuracy: 0.8949 - val_loss: 0.6101 - val_accuracy: 0.7292\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 584s 25s/step - loss: 0.2655 - accuracy: 0.8816 - val_loss: 0.3895 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 597s 25s/step - loss: 0.2210 - accuracy: 0.9062 - val_loss: 0.4068 - val_accuracy: 0.8177\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 583s 24s/step - loss: 0.2210 - accuracy: 0.9029 - val_loss: 0.4184 - val_accuracy: 0.8073\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 588s 25s/step - loss: 0.2288 - accuracy: 0.9043 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 588s 25s/step - loss: 0.2223 - accuracy: 0.9176 - val_loss: 0.4515 - val_accuracy: 0.8073\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 656s 28s/step - loss: 0.2291 - accuracy: 0.9029 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 657s 28s/step - loss: 0.2108 - accuracy: 0.9003 - val_loss: 0.3435 - val_accuracy: 0.8438\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 645s 27s/step - loss: 0.2119 - accuracy: 0.9269 - val_loss: 0.4476 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nida\\\\Downloads\\\\archive (1)\\\\8863\\\\1\\\\8863_idx5_x1001_y801_class1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6652\\2586135925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m# Example usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\Users\\Nida\\Downloads\\archive (1)\\8863\\1\\8863_idx5_x1001_y801_class1.jpg'\u001b[0m  \u001b[1;31m# Update this path to the image you want to predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[0mpredict_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6652\\2586135925.py\u001b[0m in \u001b[0;36mpredict_image\u001b[1;34m(image_path, model)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m# Function to predict a single image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Nida\\\\Downloads\\\\archive (1)\\\\8863\\\\1\\\\8863_idx5_x1001_y801_class1.jpg'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Data preparation\n",
    "data_dir = r'C:\\Users\\Nida\\Downloads\\archive (1)\\8863' # Update with the actual path\n",
    "\n",
    "# Image data generators with more augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Function to predict a single image\n",
    "def predict_image(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    if prediction > 0.5:\n",
    "        print(f\"The image {os.path.basename(image_path)} is predicted to be Malignant\")\n",
    "    else:\n",
    "        print(f\"The image {os.path.basename(image_path)} is predicted to be Benign\")\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\Nida\\Downloads\\archive (1)\\8863\\1\\8863_idx5_x1001_y801_class1.jpg'  # Update this path to the image you want to predict\n",
    "predict_image(image_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d40d536-3981-4059-a5da-7945a2fb5ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The image 8863_idx5_x51_y1251_class0.png is predicted to be Benign\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = r'C:\\Users\\Nida\\Downloads\\archive (1)\\8863\\0\\8863_idx5_x51_y1251_class0.png'  # Update this path to the image you want to predict\n",
    "predict_image(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ab3c61e-ed55-4f2f-8f52-c909a39840c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6652\\1038110276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Evaluate the model on the validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mval_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mval_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_generator' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_generator.reset()\n",
    "val_steps = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "y_true = val_generator.classes\n",
    "y_pred = model.predict(val_generator, steps=val_steps)\n",
    "y_pred = np.round(y_pred).astype(int).reshape(-1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Benign', 'Malignant']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e38ad3d1-6bd0-4294-a916-429f90ffa932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 126s 22s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [195, 192]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6652\\4183633823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Calculate accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy: {accuracy}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y_pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    398\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [195, 192]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "validation_generator.reset()\n",
    "val_steps = validation_generator.samples // validation_generator.batch_size\n",
    "\n",
    "# Getting true labels and predictions\n",
    "y_true = validation_generator.classes\n",
    "y_pred = model.predict(validation_generator, steps=val_steps)\n",
    "y_pred = np.round(y_pred).astype(int).reshape(-1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Benign', 'Malignant']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c664f858-a876-4e1b-ac08-941deb218f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nida\\anaconda3\\lib\\site-packages (2.10.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nida\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\nida\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nida\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nida\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "940976f3-36f6-4276-b623-f17f66d5e197",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_2. Consider increasing the input size. Received input shape [None, 30, 1, 1] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6652\\1434026599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Create the CNN model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    348\u001b[0m                 \u001b[1;34mf\"One of the dimensions in the output is <= 0 \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[1;34mf\"due to downsampling in {self.name}. Consider \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_2. Consider increasing the input size. Received input shape [None, 30, 1, 1] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the WDBC dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Preprocess the data\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "y = np.where(y == 'M', 1, 0)  # Convert labels to binary format (Malignant = 1, Benign = 0)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data to fit the CNN input requirements (CNN expects 3D input)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1, 1)\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1], 1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int).reshape(-1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# You should see an accuracy close to or above 96%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "823b56cd-ea80-47bb-bb74-01438d09984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 3s 36ms/step - loss: 0.7643 - accuracy: 0.5582 - val_loss: 0.6519 - val_accuracy: 0.5965\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.7565 - accuracy: 0.4989 - val_loss: 0.6332 - val_accuracy: 0.6140\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6984 - accuracy: 0.5736 - val_loss: 0.6146 - val_accuracy: 0.6404\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6917 - accuracy: 0.5846 - val_loss: 0.5971 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6942 - accuracy: 0.5824 - val_loss: 0.5802 - val_accuracy: 0.7193\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.6532 - accuracy: 0.6110 - val_loss: 0.5646 - val_accuracy: 0.7544\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6791 - accuracy: 0.5868 - val_loss: 0.5503 - val_accuracy: 0.7807\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6208 - accuracy: 0.5956 - val_loss: 0.5369 - val_accuracy: 0.7982\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6182 - accuracy: 0.6198 - val_loss: 0.5256 - val_accuracy: 0.8158\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6294 - accuracy: 0.6220 - val_loss: 0.5131 - val_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6081 - accuracy: 0.6484 - val_loss: 0.5023 - val_accuracy: 0.8509\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.6052 - accuracy: 0.6352 - val_loss: 0.4914 - val_accuracy: 0.8596\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6374 - accuracy: 0.6330 - val_loss: 0.4806 - val_accuracy: 0.8947\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.6264 - val_loss: 0.4709 - val_accuracy: 0.8947\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5797 - accuracy: 0.6330 - val_loss: 0.4618 - val_accuracy: 0.9123\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5733 - accuracy: 0.6901 - val_loss: 0.4533 - val_accuracy: 0.9123\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5658 - accuracy: 0.6923 - val_loss: 0.4452 - val_accuracy: 0.9211\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.6637 - val_loss: 0.4372 - val_accuracy: 0.9386\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.6769 - val_loss: 0.4288 - val_accuracy: 0.9386\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7297 - val_loss: 0.4209 - val_accuracy: 0.9474\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the WDBC dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Preprocess the data\n",
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "y = np.where(y == 'M', 1, 0)  # Convert labels to binary format (Malignant = 1, Benign = 0)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int).reshape(-1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# You should see an accuracy close to or above 96%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013356f-4bf5-4e1a-9bbb-54e6c5a6f28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
